{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d610601f-de60-463e-a20e-fe8060735c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "client = OpenAI()\n",
    "\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17b7dbb7-49fd-4c5a-8040-b769d5b66f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV files\n",
    "old_testament_df = pd.read_csv('old_testament.csv')\n",
    "new_testament_df = pd.read_csv('new_testament.csv')\n",
    "\n",
    "# Initialize batch parameters\n",
    "batch_size = 100\n",
    "max_retries = 5\n",
    "\n",
    "# Function to generate embeddings for a given DataFrame\n",
    "def generate_embeddings(df, testament_name):\n",
    "    verses = df['Verse Text'].tolist()\n",
    "    embeddings = []\n",
    "    print(f\"\\nGenerating embeddings for the {testament_name}...\")\n",
    "    for i in tqdm(range(0, len(verses), batch_size)):\n",
    "        batch_verses = verses[i:i+batch_size]\n",
    "        batch_verses = [text.replace(\"\\n\", \" \") for text in batch_verses]\n",
    "        retries = 0\n",
    "        while True:\n",
    "            try:\n",
    "                response = client.embeddings.create(input = batch_verses, model=\"text-embedding-3-small\") #.data[0].embedding\n",
    "                # print(response)\n",
    "                # response = client.Embedding.create(input=batch_verses, model=\"text-embedding-ada-002\")\n",
    "                batch_embeddings = [response.data[i].embedding for i, data_point in enumerate(response.data)]\n",
    "                embeddings.extend(batch_embeddings)\n",
    "                # time.sleep(0.5)  # Pause to respect rate limits\n",
    "                break\n",
    "            except openai.RateLimitError:\n",
    "                retries += 1\n",
    "                if retries > max_retries:\n",
    "                    print(f\"Exceeded maximum retries for batch starting at index {i}.\")\n",
    "                    raise\n",
    "                wait_time = 2 ** retries\n",
    "                print(f\"Rate limit error. Retrying in {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            except Exception as e:\n",
    "                print(f\"An unexpected error occurred: {e}\")\n",
    "                raise\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "466d9340-8ba8-48c8-bef5-1c6e12d0adae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Old Testament embeddings saved to 'old_testament_embeddings.npy'.\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the Old Testament\n",
    "old_testament_embeddings = generate_embeddings(old_testament_df, \"Old Testament\")\n",
    "\n",
    "# Convert to NumPy array and save\n",
    "old_embeddings_array = np.array(old_testament_embeddings / np.linalg.norm(old_testament_embeddings, axis=-1, keepdims=True))\n",
    "np.save('normed_small_embeddings_ot.npy', old_embeddings_array)\n",
    "print(\"\\nOld Testament embeddings saved to 'normed_small_embeddings_ot.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "283db856-3513-460a-b8bd-2f1e42f4c7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the New Testament...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [01:11<00:00,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New Testament embeddings saved to 'new_testament_embeddings.npy'.\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for the New Testament\n",
    "new_testament_embeddings = generate_embeddings(new_testament_df, \"New Testament\")\n",
    "\n",
    "# Convert to NumPy array and save\n",
    "new_embeddings_array = np.array(new_testament_embeddings / np.linalg.norm(new_testament_embeddings, axis=-1, keepdims=True))\n",
    "np.save('normed_small_embeddings_nt.npy', new_embeddings_array)\n",
    "print(\"\\nNew Testament embeddings saved to 'normed_small_embeddings_nt.npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff01a97-e89f-4202-875f-a91b95329b09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
